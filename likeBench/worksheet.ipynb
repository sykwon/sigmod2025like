{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util as ut\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_file_name = \"job_all.sql\"\n",
    "tab_dot_col_list = ['mc.note', 't.title', 'n.name', 'lt.link']\n",
    "conn, cur = ut.get_db_connecter()\n",
    "tables = ut.get_table(cur)\n",
    "schema = ut.get_all_schema(cur)\n",
    "short_cut_dict = ut.get_short_cut_dict(cur)\n",
    "sql_queries = ut.read_strings(sql_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'an': 'aka_name',\n",
       " 'at': 'aka_title',\n",
       " 'ci': 'cast_info',\n",
       " 'chn': 'char_name',\n",
       " 'cct': 'comp_cast_type',\n",
       " 'cn': 'company_name',\n",
       " 'ct': 'company_type',\n",
       " 'cc': 'complete_cast',\n",
       " 'it': 'info_type',\n",
       " 'k': 'keyword',\n",
       " 'kt': 'kind_type',\n",
       " 'lt': 'link_type',\n",
       " 'mc': 'movie_companies',\n",
       " 'mi': 'movie_info',\n",
       " 'mii': 'movie_info_idx',\n",
       " 'mk': 'movie_keyword',\n",
       " 'ml': 'movie_link',\n",
       " 'n': 'name',\n",
       " 'pi': 'person_info',\n",
       " 'rt': 'role_type',\n",
       " 't': 'title'}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_cut_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:47<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "attached_sql_queries_all = ut.attach_con_sels(cur, sql_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "attached_sql_queries = ut.filter_attached_sql_with_like_columns(attached_sql_queries_all, tab_dot_col_list)\n",
    "sql_sets = set([x[0] for x in attached_sql_queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"job_LPLM.sql\", 'w') as f:\n",
    "    for sql_query in sorted(sql_sets):\n",
    "        f.write(sql_query + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 149978.14it/s]\n",
      "100%|██████████| 59/59 [00:00<00:00, 9206.25it/s]\n"
     ]
    }
   ],
   "source": [
    "cond_pred_dict_all = ut.get_cond_pred_dict_from_attached_sql_queries(attached_sql_queries)\n",
    "cond_pred_dict = ut.get_cond_pred_dict_from_attached_sql_queries(attached_sql_queries, tab_dot_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"ct.kind = 'production companies'\": 0.005,\n",
       " \"it.info = 'bottom 10 rank'\": 0.008929,\n",
       " \"mc.note !~~ '%(as Metro-Goldwyn-Mayer Pictures)%'\": 0.514131,\n",
       " 't.production_year > 2000': 0.551089,\n",
       " \"mc.note !~~ '%(TV)%'\": 0.358804,\n",
       " \"mc.note ~~ '%(USA)%'\": 0.194591,\n",
       " 't.production_year > 1990': 0.694659,\n",
       " \"cn.country_code <> '[pl]'\": 0.893967,\n",
       " \"cn.name ~~ '%Film%'\": 0.181588,\n",
       " \"cn.name ~~ '%Warner%'\": 0.010255,\n",
       " \"k.keyword = 'sequel'\": 7e-06,\n",
       " \"lt.link ~~ '%follows%'\": 0.0001,\n",
       " \"t.title ~~ '%Money%'\": 9.3e-05,\n",
       " 't.production_year = 1998': 0.018933,\n",
       " \"mc.note ~~ '%(theatrical)%'\": 0.107915,\n",
       " \"mc.note ~~ '%(France)%'\": 0.011542,\n",
       " 't.production_year > 2005': 0.404304,\n",
       " \"k.keyword = 'character-name-in-title'\": 7e-06,\n",
       " \"n.name ~~ '%Bert%'\": 0.0001,\n",
       " \"cn1.country_code = '[nl]'\": 0.010233,\n",
       " \"it1.info = 'rating'\": 0.008929,\n",
       " \"it2.info = 'rating'\": 0.008929,\n",
       " \"kt1.kind = 'tv series'\": 0.005,\n",
       " \"kt2.kind = 'tv series'\": 0.005,\n",
       " \"lt.link ~~ '%follow%'\": 0.00032,\n",
       " \"mi_idx2.info < '3.0'\": 0.481213,\n",
       " 't2.production_year = 2007': 0.0467,\n",
       " \"n.name ~~ '%B%'\": 0.10101,\n",
       " \"cn.country_code = '[us]'\": 0.3604,\n",
       " \"it.info = 'release dates'\": 0.008929,\n",
       " \"mc.note ~~ '%(worldwide)%'\": 0.03649,\n",
       " \"mi.info ~~ 'Japan:%200%'\": 0.005232,\n",
       " \"mi.info ~~ 'USA:%200%'\": 0.05232,\n",
       " \"n.name ~~ '%Ang%'\": 0.0001,\n",
       " \"n.gender = 'f'\": 0.2303,\n",
       " \"rt.role = 'actress'\": 0.005,\n",
       " 't.production_year >= 2005': 0.443698,\n",
       " 't.production_year <= 2009': 0.760971,\n",
       " \"cct2.kind = 'complete+verified'\": 0.005,\n",
       " \"it1.info = 'genres'\": 0.008929,\n",
       " \"it2.info = 'votes'\": 0.008929,\n",
       " \"n.gender = 'm'\": 0.421667,\n",
       " \"t.title ~~ '%Freddy%'\": 9.3e-05,\n",
       " \"t.title ~~ '%Jason%'\": 9.3e-05,\n",
       " \"t.title ~~ 'Saw%'\": 0.009414,\n",
       " \"an.name ~~ '%a%'\": 0.76517,\n",
       " \"it.info = 'mini biography'\": 0.008929,\n",
       " \"lt.link = 'features'\": 0.005,\n",
       " \"n.name_pcode_cf >= 'A'\": 0.999909,\n",
       " \"n.name_pcode_cf <= 'F'\": 0.26841,\n",
       " \"n.name ~~ 'B%'\": 0.080808,\n",
       " \"pi.note = 'Volker Boehm'\": 1e-05,\n",
       " 't.production_year >= 1980': 0.774757,\n",
       " 't.production_year <= 1995': 0.332393,\n",
       " \"cct1.kind = 'cast'\": 0.005,\n",
       " \"it3.info = 'trivia'\": 0.008929,\n",
       " \"k.keyword = 'computer-animation'\": 7e-06,\n",
       " \"n.name ~~ '%An%'\": 0.040404,\n",
       " 't.production_year >= 2000': 0.572783,\n",
       " 't.production_year <= 2010': 0.816682,\n",
       " \"cct2.kind = 'complete'\": 0.005,\n",
       " 't.production_year >= 1950': 0.909068,\n",
       " 't.production_year <= 2000': 0.420911,\n",
       " \"cn.country_code <> '[us]'\": 0.539,\n",
       " \"it1.info = 'countries'\": 0.008929,\n",
       " \"mc.note !~~ '%(USA)%'\": 0.319576,\n",
       " \"mc.note ~~ '%(200%)%'\": 0.172886,\n",
       " \"mi_idx.info < '7.0'\": 0.847803,\n",
       " 't.production_year > 2008': 0.263573,\n",
       " \"cct1.kind = 'crew'\": 0.005,\n",
       " \"cct2.kind <> 'complete+verified'\": 0.995,\n",
       " \"mi_idx.info < '8.5'\": 0.969227,\n",
       " \"cn.name = 'DreamWorks Animation'\": 5e-06,\n",
       " \"mi.info ~~ 'Japan:%201%'\": 5.2e-05,\n",
       " \"mi.info ~~ 'USA:%201%'\": 0.010464,\n",
       " 't.production_year > 2010': 0.155318,\n",
       " \"t.title ~~ 'Kung Fu Panda%'\": 9.3e-05,\n",
       " \"k.keyword = 'marvel-cinematic-universe'\": 7e-06,\n",
       " \"n.name ~~ '%Downey%Robert%'\": 0.0001,\n",
       " 't.production_year > 2014': 1e-05,\n",
       " \"it.info = 'top 250 rank'\": 0.008929,\n",
       " \"mc.note ~~ '%(co-production)%'\": 0.006735,\n",
       " \"mc.note ~~ '%(presents)%'\": 0.003302,\n",
       " \"ci.note = '(voice: English version)'\": 0.003033,\n",
       " \"cn.country_code = '[jp]'\": 0.028867,\n",
       " \"mc.note ~~ '%(Japan)%'\": 0.010928,\n",
       " \"n1.name ~~ '%Yo%'\": 0.010101,\n",
       " \"n1.name !~~ '%Yu%'\": 0.9999,\n",
       " \"it.info = 'rating'\": 0.008929,\n",
       " \"it2.info = 'release dates'\": 0.008929,\n",
       " \"kt.kind = 'movie'\": 0.005,\n",
       " \"t.title <> ''\": 0.999994,\n",
       " \"t.title ~~ '%Champion%'\": 9.3e-05,\n",
       " \"t.title ~~ '%Loser%'\": 9.3e-05,\n",
       " \"n.name ~~ 'Z%'\": 0.010101,\n",
       " 't.production_year > 2009': 0.211029,\n",
       " \"chn.name = 'Queen'\": 0.0,\n",
       " \"it3.info = 'height'\": 0.008929,\n",
       " 't.production_year <= 2005': 0.567696,\n",
       " \"t.title = 'Shrek 2'\": 6e-06,\n",
       " \"n.name_pcode_cf ~~ 'D%'\": 0.046536,\n",
       " 't.production_year <= 1984': 0.228979,\n",
       " \"n.name ~~ 'X%'\": 0.0001,\n",
       " \"ci.note = '(voice)'\": 0.0199,\n",
       " \"n.name ~~ '%Angel%'\": 0.0001,\n",
       " 't.production_year >= 2007': 0.358911,\n",
       " \"mi_idx.info > '6.5'\": 0.228485,\n",
       " \"mi.info = 'Horror'\": 0.002567,\n",
       " \"t.title ~~ 'Vampire%'\": 9.3e-05,\n",
       " \"cn.name = 'YouTube'\": 5e-06,\n",
       " \"it1.info = 'release dates'\": 0.008929,\n",
       " \"mi.note ~~ '%internet%'\": 0.000906,\n",
       " \"mi.info ~~ 'USA:% 200%'\": 0.05232,\n",
       " \"mc.note ~~ '%(VHS)%'\": 0.021571,\n",
       " \"mc.note ~~ '%(1994)%'\": 0.003581,\n",
       " \"mi.info ~~ 'Japan:%2007%'\": 5.2e-05,\n",
       " \"mi.info ~~ 'USA:%2008%'\": 5.2e-05,\n",
       " 't.production_year <= 2008': 0.708427,\n",
       " \"t.title ~~ '%Kung%Fu%Panda%'\": 9.3e-05,\n",
       " \"t.title ~~ 'Champion%'\": 9.3e-05,\n",
       " \"t.title ~~ 'Loser%'\": 9.3e-05,\n",
       " 't.production_year <= 2015': 0.971993,\n",
       " \"cn.name ~~ 'Lionsgate%'\": 0.0001,\n",
       " \"mc.note ~~ '%(Blu-ray)%'\": 0.003581,\n",
       " \"mi_idx.info > '6.0'\": 0.277533,\n",
       " \"t.title ~~ '%murder%'\": 9.3e-05,\n",
       " \"t.title ~~ '%Murder%'\": 9.3e-05,\n",
       " \"t.title ~~ '%Mord%'\": 9.3e-05,\n",
       " \"mc.note ~~ '%(2006)%'\": 0.02359,\n",
       " \"mc.note ~~ '%(2007)%'\": 0.024557,\n",
       " \"n.name ~~ '%Yo%'\": 0.010101,\n",
       " \"n.name !~~ '%Yu%'\": 0.9999,\n",
       " 't.production_year >= 2006': 0.404954,\n",
       " 't.production_year <= 2007': 0.66045,\n",
       " \"t.title ~~ 'One Piece%'\": 9.3e-05,\n",
       " \"t.title ~~ 'Dragon Ball Z%'\": 9.3e-05,\n",
       " \"ct.kind = 'distributors'\": 0.005,\n",
       " \"it1.info = 'budget'\": 0.008929,\n",
       " \"it2.info = 'bottom 10 rank'\": 0.008929,\n",
       " \"t.title ~~ 'Birdemic%'\": 9.3e-05,\n",
       " \"t.title ~~ '%Movie%'\": 9.3e-05,\n",
       " \"an.name ~~ 'A%'\": 0.040679,\n",
       " \"n.name ~~ 'A%'\": 0.040404,\n",
       " \"cct2.kind ~~ 'complete%'\": 0.005,\n",
       " \"cct2.kind ~~ '%complete%'\": 0.0001,\n",
       " \"chn.name !~~ '%Sherlock%'\": 0.9999,\n",
       " \"chn.name ~~ '%Tony%Stark%'\": 0.0001,\n",
       " \"chn.name ~~ '%Iron%Man%'\": 0.0001,\n",
       " \"n.name ~~ '%Tim%'\": 0.0001}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_pred_dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cond_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_list = list(cond_pred_dict)\n",
    "table_col_dict = ut.get_table_col_dict_from_cond_list(cond_list, cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mc', 'note'): ['%(1994)%',\n",
       "  '%(200%)%',\n",
       "  '%(2006)%',\n",
       "  '%(2007)%',\n",
       "  '%(Blu-ray)%',\n",
       "  '%(France)%',\n",
       "  '%(Japan)%',\n",
       "  '%(TV)%',\n",
       "  '%(USA)%',\n",
       "  '%(VHS)%',\n",
       "  '%(as Metro-Goldwyn-Mayer Pictures)%',\n",
       "  '%(co-production)%',\n",
       "  '%(presents)%',\n",
       "  '%(theatrical)%',\n",
       "  '%(worldwide)%'],\n",
       " ('lt', 'link'): ['%follow%', '%follows%', 'features'],\n",
       " ('t', 'title'): ['%Champion%',\n",
       "  '%Freddy%',\n",
       "  '%Jason%',\n",
       "  '%Kung%Fu%Panda%',\n",
       "  '%Loser%',\n",
       "  '%Money%',\n",
       "  '%Mord%',\n",
       "  '%Movie%',\n",
       "  '%Murder%',\n",
       "  '%murder%',\n",
       "  'Birdemic%',\n",
       "  'Champion%',\n",
       "  'Dragon Ball Z%',\n",
       "  'Kung Fu Panda%',\n",
       "  'Loser%',\n",
       "  'One Piece%',\n",
       "  'Saw%',\n",
       "  'Shrek 2',\n",
       "  'Vampire%'],\n",
       " ('n', 'name'): ['%An%',\n",
       "  '%Ang%',\n",
       "  '%Angel%',\n",
       "  '%B%',\n",
       "  '%Bert%',\n",
       "  '%Downey%Robert%',\n",
       "  '%Tim%',\n",
       "  '%Yo%',\n",
       "  '%Yu%',\n",
       "  'A%',\n",
       "  'B%',\n",
       "  'X%',\n",
       "  'Z%']}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_col_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count rows (all, not null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_type 17\n",
      "movie_companies 2609128\n",
      "name 4167490\n",
      "title 2528311\n",
      "link_type 17\n",
      "movie_companies 1337139\n",
      "name 4167490\n",
      "title 2528311\n"
     ]
    }
   ],
   "source": [
    "for table in ['link_type', 'movie_companies', 'name', 'title']:\n",
    "    print(table, ut.get_count_data_strings_from_table(table, cur))\n",
    "\n",
    "for table, col in [('link_type', 'link'), ('movie_companies', 'note'), ('name', 'name'), ('title', 'title')]:\n",
    "    print(table, ut.get_count_data_strings_from_table_col(table, col, cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect columns and predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('movie_companies', 'note') ['(2006) (worldwide) (TV)', '(2012) (worldwide) (all media)']\n",
      "data_filepath = 'data/movie_companies.note/movie_companies.note.txt'\n",
      "test_filepath = 'data/movie_companies.note/query/CEB/test.txt'\n",
      "('link_type', 'link') ['followed by', 'remake of']\n",
      "data_filepath = 'data/link_type.link/link_type.link.txt'\n",
      "test_filepath = 'data/link_type.link/query/CEB/test.txt'\n",
      "('title', 'title') [\"Josie Duggar's 1st Shoes\", '(#2.8)']\n",
      "data_filepath = 'data/title.title/title.title.txt'\n",
      "test_filepath = 'data/title.title/query/CEB/test.txt'\n",
      "('name', 'name') ['A., David', '-Alverio, Esteban Rodriguez']\n",
      "data_filepath = 'data/name.name/name.name.txt'\n",
      "test_filepath = 'data/name.name/query/CEB/test.txt'\n"
     ]
    }
   ],
   "source": [
    "table_col_dict\n",
    "\n",
    "for table_col, test_queries in table_col_dict.items():\n",
    "    data_strings = ut.get_data_strings_from_table_col(table_col, cur)\n",
    "    print(table_col, data_strings[:2])\n",
    "    table, col = table_col\n",
    "    data_name = f\"{table}.{col}\"\n",
    "    data_filepath = f\"data/{data_name}/{data_name}.txt\"\n",
    "    test_filepath = f\"data/{data_name}/query/CEB/test.txt\"\n",
    "    os.makedirs(os.path.dirname(data_filepath), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(test_filepath), exist_ok=True)\n",
    "\n",
    "    print(f\"{data_filepath = }\")\n",
    "    with open(data_filepath, 'w') as f:\n",
    "        for data_string in data_strings:\n",
    "            if data_string is None:\n",
    "                data_string = ''\n",
    "            f.write(data_string + \"\\n\")\n",
    "\n",
    "    print(f\"{test_filepath = }\")\n",
    "    with open(test_filepath, 'w') as f:\n",
    "        for test_query in test_queries:\n",
    "            f.write(test_query + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_type(x):\n",
    "    if '%' in x or '_' in  x:\n",
    "        return x\n",
    "    else:\n",
    "        return 'w'\n",
    "\n",
    "def get_pattern_len_info(query):\n",
    "    parsed = ut.parse_like_query(query)\n",
    "    output = []\n",
    "    for token in parsed:\n",
    "        if '%' not in token and '_' not in token:\n",
    "            output.append(len(token))\n",
    "    return output\n",
    "\n",
    "def make_pattern(query):\n",
    "    parsed = ut.parse_like_query(query)\n",
    "    # pattern_tokens = ['w' if '_' not in x and '%' not in x else x for x in parsed]\n",
    "    pattern_tokens = [token_type(x) for x in parsed]\n",
    "    pattern = ''.join(pattern_tokens)\n",
    "\n",
    "    return pattern\n",
    "\n",
    "def get_pattern_info(queries):\n",
    "    pattern_dict = {}\n",
    "    for query in queries:\n",
    "        pattern = make_pattern(query)\n",
    "        pattern_len_info = get_pattern_len_info(query)\n",
    "        if pattern not in pattern_dict:\n",
    "            pattern_dict[pattern] = set()\n",
    "        pattern_dict[pattern].add(tuple(pattern_len_info))\n",
    "    \n",
    "    # pattern_dict = {x: [list(t) for t in y] for x, y in pattern_dict.items()}\n",
    "    pattern_dict = {x: list(sorted(y, key=lambda x: x[-1])) for x, y in pattern_dict.items()}\n",
    "    pattern_dict = {x: list(sorted(y, key=lambda x: x[0])) for x, y in pattern_dict.items()}\n",
    "    # pattern_dict = {x: list(zip(*y)) for x, y in pattern_dict.items()}\n",
    "    return pattern_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_type.link\n",
      "{'%w%': [(6,), (7,)], 'w': [(8,)]}\n",
      "movie_companies.note\n",
      "{'%w%': [(4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (15,), (33,)], '%w%w%': [(4, 1)]}\n",
      "name.name\n",
      "{'%w%': [(1,), (2,), (3,), (4,), (5,)], '%w%w%': [(6, 6)], 'w%': [(1,)]}\n",
      "title.title\n",
      "{'%w%': [(4,), (5,), (6,), (8,)], '%w%w%w%': [(4, 2, 5)], 'w%': [(3,), (5,), (7,), (8,), (9,), (13,)], 'w': [(7,)]}\n"
     ]
    }
   ],
   "source": [
    "column_names = sorted(os.listdir('data/'))\n",
    "for column_name in column_names:\n",
    "    print(column_name)\n",
    "    query_path = f'data/{column_name}/query/CEB/test.txt'\n",
    "    queries = ut.read_strings(query_path)\n",
    "    pattern_dict = get_pattern_info(queries)\n",
    "    workload_path = f'data/{column_name}/query/CEB/workload.yml'\n",
    "    print(pattern_dict)\n",
    "    with open(workload_path, 'w') as f:\n",
    "        yaml.dump(pattern_dict, f, default_flow_style=False)\n",
    "    # for query in queries:\n",
    "    #     pattern = make_pattern(query)\n",
    "    \n",
    "    # print(queries[0])\n",
    "    # print(ut.parse_like_query(queries[0]))\n",
    "    # print(make_pattern(queries[0]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gen train data from pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_query_a(data_string, pattern, pattern_len_info):\n",
    "#     pass\n",
    "\n",
    "def gen_query(db, pattern, pattern_len_info, n_repeat=1):\n",
    "    def get_range(len_ranges, w_id, remain_range=[1, 1e6], remain_min_lens=[]):\n",
    "        allowed_len = remain_range[1] - remain_range[0] + 1 - sum(remain_min_lens)\n",
    "        if allowed_len <= 0:\n",
    "            print(f\"{remain_range = }\")\n",
    "            print(f\"{remain_min_lens = }\")\n",
    "            print(f\"{len_ranges = }\")\n",
    "            print(f\"{w_id = }\")\n",
    "        assert allowed_len > 0, allowed_len\n",
    "        min_len = min(len_ranges[w_id][0], allowed_len)\n",
    "        max_len = min(len_ranges[w_id][1], allowed_len)\n",
    "        return min_len, max_len\n",
    "\n",
    "    parsed = ut.parse_like_query(pattern)\n",
    "    n_words = parsed.count('w')\n",
    "    if parsed[0] == '%' and parsed[-1] == '%':\n",
    "        query_type = 'substring'\n",
    "    elif parsed[-1] == '%':\n",
    "        query_type = 'prefix'\n",
    "    elif parsed[0] == '%':\n",
    "        query_type = 'suffix'\n",
    "    elif n_words == 1:\n",
    "        query_type = 'exact'\n",
    "    \n",
    "\n",
    "    output = set()\n",
    "    len_ranges = [[min(x), max(max(x), min(x) + 1)] for x in list(zip(*pattern_len_info))]\n",
    "    np.random.seed(0)\n",
    "    if query_type == 'exact':\n",
    "        assert n_words == 1\n",
    "        min_len, max_len = len_ranges[0]\n",
    "        for data_string in db:\n",
    "            if '_' in data_string or '%' in data_string:\n",
    "                continue\n",
    "            if len(data_string) <= max_len + 2:\n",
    "                output.add(data_string)\n",
    "        output = list(output)\n",
    "        return output\n",
    "\n",
    "    if n_repeat > 1:\n",
    "        db = db * n_repeat\n",
    "        \n",
    "    for data_string in tqdm(db):\n",
    "        if '_' in data_string or '%' in data_string:\n",
    "            continue\n",
    "        predicate = None\n",
    "\n",
    "        remain_range = [1, len(data_string)]\n",
    "        tokens = []\n",
    "\n",
    "        # get all min_len\n",
    "        min_lens = []\n",
    "        for w_id in range(n_words):\n",
    "            min_len, max_len = get_range(len_ranges, w_id)\n",
    "            min_lens.append(min_len)\n",
    "        if sum(min_lens) > len(data_string):\n",
    "            continue\n",
    "        # print(\"start query gen\")\n",
    "        # print(f\"{min_lens = }\")\n",
    "        # print(f\"{len(data_string) = }\")\n",
    "\n",
    "        if query_type == 'suffix':\n",
    "            w_id = n_words - 1\n",
    "            min_lens.pop()\n",
    "            min_len, max_len = get_range(len_ranges, w_id, remain_range, min_lens)\n",
    "            length = np.random.randint(min_len, max_len+1)\n",
    "            last_token = data_string[-length:]\n",
    "            remain_range = [remain_range[0], remain_range[1] - len(last_token)]\n",
    "        \n",
    "        \n",
    "        for w_id in range(n_words):\n",
    "            if len(min_lens) > 0:\n",
    "                min_lens.pop(0)\n",
    "\n",
    "            min_len, max_len = get_range(len_ranges, w_id, remain_range, min_lens)\n",
    "            if query_type == 'prefix' and w_id == 0:\n",
    "                length = np.random.randint(min_len, max_len+1)\n",
    "                token = data_string[:length]\n",
    "                remain_range = [remain_range[0] + len(token), remain_range[1]]\n",
    "            elif query_type == 'suffix' and w_id == range(n_words) - 1:\n",
    "                token = last_token\n",
    "            else: # substring\n",
    "                length = np.random.randint(min_len, max_len+1)\n",
    "                # print(f\"{n_words = }\")\n",
    "                # print(f\"{length = }\")\n",
    "                # print(f\"{remain_range = }\")\n",
    "                # print(f\"{min_lens = }\")\n",
    "                # print(f\"{sum(min_lens) = }\")\n",
    "                # print(f\"{remain_range[0], (remain_range[1] + 1) - length + 1 - sum(min_lens) = }\")\n",
    "                start_pos = np.random.randint(remain_range[0], (remain_range[1] + 1) - length + 1 - sum(min_lens))\n",
    "                start_idx = start_pos - 1\n",
    "                token = data_string[start_idx: start_idx+length]\n",
    "                remain_range = [start_pos + length, remain_range[1]]\n",
    "        \n",
    "            tokens.append(token)\n",
    "                \n",
    "        # tokens = [re.sub('%|_', '', token) for token in tokens]\n",
    "        predicate = '%'.join(tokens)\n",
    "        if query_type == 'prefix':\n",
    "            predicate = predicate + \"%\"\n",
    "        elif query_type == 'suffix':\n",
    "            predicate = \"%\" + predicate\n",
    "        else:\n",
    "            predicate = \"%\" + predicate + \"%\"\n",
    "            \n",
    "        output.add(predicate)\n",
    "    output = list(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title.title\n",
      "{'%w%': [(4,), (5,), (6,), (8,)], '%w%w%w%': [(4, 2, 5)], 'w': [(7,)], 'w%': [(3,), (5,), (7,), (8,), (9,), (13,)]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2528311/2528311 [00:37<00:00, 67895.23it/s]\n",
      "100%|██████████| 2528311/2528311 [01:09<00:00, 36302.00it/s]\n",
      "100%|██████████| 2528311/2528311 [00:29<00:00, 84820.49it/s]\n"
     ]
    }
   ],
   "source": [
    "column_names = sorted(os.listdir('data/'))\n",
    "# column_names = [\"movie_companies.note\", \"title.title\", \"name.name\", \"link_type.link\"]\n",
    "# column_names = [\"title.title\"]\n",
    "column_names = [\"title.title\"]\n",
    "for column_name in column_names:\n",
    "    print(column_name)\n",
    "    data_path = f'data/{column_name}/{column_name}.txt'\n",
    "    db = ut.read_strings(data_path)\n",
    "    workload_path = f'data/{column_name}/query/CEB/workload.yml'\n",
    "    test_path = f'data/{column_name}/query/CEB/test.txt'\n",
    "    valid_path = f'data/{column_name}/query/CEB/valid.txt'\n",
    "    train_path = f'data/{column_name}/query/CEB/train.txt'\n",
    "    test_queries = ut.read_strings(test_path)\n",
    "    n_repeat = 1000 if column_name == 'link_type.link' else 1\n",
    "    with open(workload_path) as f:\n",
    "        workload = yaml.load(f, yaml.FullLoader)\n",
    "    print(workload)\n",
    "    # print(pattern_dict)\n",
    "    # with open(workload_path, 'w') as f:\n",
    "    #     yaml.dump(pattern_dict, f, default_flow_style=False)\n",
    "\n",
    "    p_valid = 0.1\n",
    "    \n",
    "    train_queries = []\n",
    "    valid_queries = []\n",
    "    for pattern, pattern_len_info in workload.items():\n",
    "        generated_queries = gen_query(db, pattern, pattern_len_info, n_repeat)\n",
    "        generated_queries = list(set(generated_queries) - set(test_queries))\n",
    "        train_queries_part, valid_queries_part = train_test_split(generated_queries, test_size=p_valid, random_state=0)\n",
    "        train_queries.extend(train_queries_part)\n",
    "        valid_queries.extend(valid_queries_part)\n",
    "    \n",
    "    train_queries = sorted(set(train_queries))\n",
    "    valid_queries = sorted(valid_queries)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.writelines('\\n'.join(train_queries))\n",
    "        \n",
    "    with open(valid_path, 'w') as f:\n",
    "        f.writelines('\\n'.join(valid_queries))\n",
    "    \n",
    "\n",
    "    # for query in queries:\n",
    "    #     pattern = make_pattern(query)\n",
    "    \n",
    "    # print(queries[0])\n",
    "    # print(ut.parse_like_query(queries[0]))\n",
    "    # print(make_pattern(queries[0]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  len\n",
      "158       spoofs    6\n",
      "0       % langu%    8\n",
      "95      %nguage%    8\n",
      "92      %nced i%    8\n",
      "90      %nate l%    8\n",
      "..           ...  ...\n",
      "155   similar to   10\n",
      "157   spoofed in   10\n",
      "159   version of   10\n",
      "150  featured in   11\n",
      "151  followed by   11\n",
      "\n",
      "[160 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# queries = ut.read_strings(\"data/title.title/query/CEB/train.txt\")\n",
    "queries = ut.read_strings(\"data/link_type.link/query/CEB/train.txt\")\n",
    "df = pd.DataFrame(queries)\n",
    "# print(df)\n",
    "df['len'] = df[0].apply(len)\n",
    "print(df.sort_values('len'))\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_type.link\n",
      "movie_companies.note\n",
      "name.name\n",
      "title.title\n"
     ]
    }
   ],
   "source": [
    "for column_name in column_names:\n",
    "    print(column_name)\n",
    "    valid_path = f'data/{column_name}/query/CEB/valid.txt'\n",
    "    train_path = f'data/{column_name}/query/CEB/train.txt'\n",
    "    train_queries = ut.read_strings(train_path)\n",
    "    valid_queries = ut.read_strings(valid_path)\n",
    "    train_queries = sorted(train_queries)\n",
    "    valid_queries = sorted(valid_queries)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.writelines('\\n'.join(train_queries))\n",
    "        \n",
    "    with open(valid_path, 'w') as f:\n",
    "        f.writelines('\\n'.join(valid_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Short, Too',\n",
       " 'Abdul-Hamid, Jaffar',\n",
       " 'Al-Hamid, Jaffar Abd',\n",
       " \"Viera, Michael 'Power'\",\n",
       " 'Buguelo',\n",
       " 'Seigal, Jason',\n",
       " 'Starks, Johnny',\n",
       " 'Monkey',\n",
       " \"'Morità'\",\n",
       " \"Mark'Oh\"]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.data_gen_alg_regex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!Ne%</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!Next?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!Que ve el%</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"A Corrida%</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bookstore\" (%</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273221</th>\n",
       "      <td>ìMaten a ese%</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273222</th>\n",
       "      <td>íslenska, on %</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273223</th>\n",
       "      <td>île de Sym%</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273224</th>\n",
       "      <td>ö</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273225</th>\n",
       "      <td>üç</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3273226 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0  len\n",
       "0                  !Ne%    4\n",
       "1                !Next?    6\n",
       "2           !Que ve el%   11\n",
       "3           \"A Corrida%   11\n",
       "4        \"Bookstore\" (%   14\n",
       "...                 ...  ...\n",
       "3273221   ìMaten a ese%   13\n",
       "3273222  íslenska, on %   14\n",
       "3273223     île de Sym%   11\n",
       "3273224               ö    1\n",
       "3273225              üç    2\n",
       "\n",
       "[3273226 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries = ut.read_strings(\"data/title.title/query/CEB/train.txt\")\n",
    "df = pd.DataFrame(queries)\n",
    "df['len'] = df[0].apply(len)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3273226, 3273226)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries), len(set(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_dict = {}\n",
    "for query in queries:\n",
    "    if query not in wc_dict:\n",
    "        wc_dict[query] = 0\n",
    "    wc_dict[query] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% 2\n",
      "110% 2\n",
      "200% 2\n",
      "Innocent % 2\n",
      "The 99% 2\n",
      "The Top 1% 2\n"
     ]
    }
   ],
   "source": [
    "for q, c in wc_dict.items():\n",
    "    if c > 1:\n",
    "        print(q, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clique",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
